{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEV Information Extraction\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook extracts all MEV-related information from the binary classification results, including:\n",
    "\n",
    "1. **MEV Sample Statistics**: Detailed analysis of all detected MEV samples\n",
    "2. **Top MEV Wallets**: Highest risk MEV wallets ranked by mev_score\n",
    "3. **Validator Information**: Which validators processed MEV transactions\n",
    "4. **Pool/AMM Information**: Which pools were targeted by MEV bots\n",
    "5. **PnL Analysis**: Profit and loss calculations (if available in trade data)\n",
    "6. **Visualizations**: Scatter plots showing MEV separation\n",
    "7. **Export**: CSV files with all MEV information\n",
    "\n",
    "## Input\n",
    "\n",
    "- **Source Data**: `../01_data_cleaning/outputs/pamm_clean_final.parquet`\n",
    "- **Classification Results**: Binary labels from `07a_ml_classification_binary.ipynb` (or re-computed)\n",
    "\n",
    "## Output\n",
    "\n",
    "- **MEV Samples CSV**: `derived/ml_results_binary/mev_samples_detected.csv`\n",
    "- **MEV Statistics CSV**: `derived/ml_results_binary/mev_statistics.csv`\n",
    "- **Top MEV Wallets CSV**: `derived/ml_results_binary/top_mev_wallets.csv`\n",
    "- **Visualizations**: Scatter plots and comparison charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MEV INFORMATION EXTRACTION\")\n",
    "print(\"=\"*80)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 1. DATA LOADING\n",
    "# ============================================================================\n",
    "print(\"=\"*80)\n",
    "print(\"1. DATA LOADING\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# Load cleaned data\n",
    "data_paths = [\n",
    "    '../01_data_cleaning/outputs/pamm_clean_final.parquet',\n",
    "    '../../01_data_cleaning/outputs/pamm_clean_final.parquet',\n",
    "    'notebooks/01_data_cleaning/outputs/pamm_clean_final.parquet'\n",
    "]\n",
    "\n",
    "df_clean = None\n",
    "for path in data_paths:\n",
    "    if os.path.exists(path):\n",
    "        df_clean = pd.read_parquet(path)\n",
    "        print(f\"✓ Loaded from: {path}\")\n",
    "        break\n",
    "\n",
    "if df_clean is None:\n",
    "    raise FileNotFoundError(\"Could not find pamm_clean_final.parquet in any expected location\")\n",
    "\n",
    "print(f\"✓ Loaded {len(df_clean):,} transaction records\")\n",
    "\n",
    "# Check for datetime column\n",
    "if 'datetime' in df_clean.columns:\n",
    "    print(f\"✓ Time range: {df_clean['datetime'].min()} to {df_clean['datetime'].max()}\")\n",
    "elif 'ms_time' in df_clean.columns:\n",
    "    df_clean['datetime'] = pd.to_datetime(df_clean['ms_time'], unit='ms', utc=True, errors='coerce')\n",
    "    print(f\"✓ Created datetime from ms_time\")\n",
    "    print(f\"✓ Time range: {df_clean['datetime'].min()} to {df_clean['datetime'].max()}\")\n",
    "else:\n",
    "    print(\"⚠️  No datetime column found, but continuing...\")\n",
    "\n",
    "print(f\"✓ Event types: {df_clean['kind'].value_counts().to_dict()}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 2. FEATURE ENGINEERING (Re-create signer-level features)\n",
    "# ============================================================================\n",
    "print(\"=\"*80)\n",
    "print(\"2. FEATURE ENGINEERING\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "print(\"Creating signer-level features (this may take a few minutes)...\")\n",
    "\n",
    "# Filter to TRADE events only\n",
    "df_trades = df_clean[df_clean['kind'] == 'TRADE'].copy()\n",
    "print(f\"✓ Filtered to {len(df_trades):,} TRADE events\")\n",
    "\n",
    "# Get unique signers\n",
    "unique_signers = df_trades['signer'].unique()\n",
    "print(f\"✓ Found {len(unique_signers):,} unique signers\")\n",
    "print()\n",
    "\n",
    "# Feature engineering (same logic as 07a)\n",
    "signer_features = []\n",
    "\n",
    "print(\"Processing signers...\")\n",
    "for i, signer in enumerate(unique_signers):\n",
    "    if (i + 1) % 1000 == 0:\n",
    "        print(f\"  Processed {i+1}/{len(unique_signers)} signers...\")\n",
    "    \n",
    "    signer_trades = df_trades[df_trades['signer'] == signer].copy()\n",
    "    \n",
    "    if len(signer_trades) < 2:\n",
    "        continue\n",
    "    \n",
    "    total_trades = len(signer_trades)\n",
    "    time_span_hours = (signer_trades['datetime'].max() - signer_trades['datetime'].min()).total_seconds() / 3600\n",
    "    trades_per_hour = total_trades / max(time_span_hours, 0.1)\n",
    "    \n",
    "    late_slot_trades = (signer_trades['us_since_first_shred'] > 300000).sum()\n",
    "    late_slot_ratio = late_slot_trades / total_trades\n",
    "    \n",
    "    signer_slots = signer_trades['slot'].unique()\n",
    "    oracle_backrun_count = 0\n",
    "    slot_oracles = df_clean[(df_clean['slot'].isin(signer_slots)) & \n",
    "                           (df_clean['kind'] == 'ORACLE')][['slot', 'ms_time']]\n",
    "    \n",
    "    if len(slot_oracles) > 0:\n",
    "        oracle_by_slot = slot_oracles.groupby('slot')['ms_time'].apply(list).to_dict()\n",
    "        for _, trade in signer_trades.iterrows():\n",
    "            slot = trade['slot']\n",
    "            trade_time = trade['ms_time']\n",
    "            if slot in oracle_by_slot:\n",
    "                oracle_times = oracle_by_slot[slot]\n",
    "                time_diffs = [abs(ot - trade_time) for ot in oracle_times]\n",
    "                if min(time_diffs) < 50:\n",
    "                    oracle_backrun_count += 1\n",
    "    oracle_backrun_ratio = oracle_backrun_count / total_trades if total_trades > 0 else 0\n",
    "    \n",
    "    high_bytes_trades = (signer_trades['bytes_changed_trade'] > 50).sum()\n",
    "    high_bytes_ratio = high_bytes_trades / total_trades if total_trades > 0 else 0\n",
    "    \n",
    "    slot_counts = signer_trades.groupby('slot').size()\n",
    "    clustered_slots = (slot_counts >= 2).sum()\n",
    "    cluster_ratio = clustered_slots / signer_trades['slot'].nunique() if signer_trades['slot'].nunique() > 0 else 0\n",
    "    \n",
    "    signer_slots = signer_trades['slot'].unique()\n",
    "    sample_size = min(100, len(signer_slots))\n",
    "    \n",
    "    if sample_size > 0:\n",
    "        sampled_slots = np.random.choice(signer_slots, size=sample_size, replace=False)\n",
    "        slot_trade_counts = df_trades[df_trades['slot'].isin(sampled_slots)].groupby('slot').agg({\n",
    "            'signer': ['count', 'nunique']\n",
    "        }).reset_index()\n",
    "        slot_trade_counts.columns = ['slot', 'total_trades', 'unique_signers']\n",
    "        slot_trade_counts = slot_trade_counts[slot_trade_counts['total_trades'] > 1]\n",
    "        \n",
    "        if len(slot_trade_counts) > 0:\n",
    "            slot_trade_counts['unique_ratio'] = slot_trade_counts['unique_signers'] / slot_trade_counts['total_trades']\n",
    "            aggregator_slots = (slot_trade_counts['unique_ratio'] > 0.7).sum()\n",
    "            aggregator_likelihood = aggregator_slots / len(slot_trade_counts)\n",
    "        else:\n",
    "            aggregator_likelihood = 0\n",
    "    else:\n",
    "        aggregator_likelihood = 0\n",
    "    \n",
    "    mev_score = (late_slot_ratio * 0.3 + \n",
    "                 oracle_backrun_ratio * 0.3 + \n",
    "                 high_bytes_ratio * 0.2 + \n",
    "                 cluster_ratio * 0.2)\n",
    "    \n",
    "    wash_trading_score = trades_per_hour / max(mev_score + 0.1, 0.1)\n",
    "    \n",
    "    # Classification logic\n",
    "    if aggregator_likelihood > 0.5:\n",
    "        classification = \"LIKELY AGGREGATOR (Jupiter, etc.)\"\n",
    "    elif wash_trading_score > 1.0 and mev_score < 0.2:\n",
    "        classification = \"LIKELY WASH TRADING (Volume Inflation)\"\n",
    "    elif mev_score > 0.3:\n",
    "        classification = \"LIKELY MEV BOT\"\n",
    "    elif cluster_ratio > 0.3:\n",
    "        classification = \"POSSIBLE MEV (Sandwich patterns)\"\n",
    "    else:\n",
    "        classification = \"REGULAR TRADE BOT / UNKNOWN\"\n",
    "    \n",
    "    # Binary label\n",
    "    if classification in [\"LIKELY MEV BOT\", \"POSSIBLE MEV (Sandwich patterns)\"]:\n",
    "        binary_label = 1  # MEV\n",
    "    else:\n",
    "        binary_label = 0  # Non-MEV\n",
    "    \n",
    "    # Collect validator and pool information\n",
    "    validators = signer_trades['validator'].unique().tolist()\n",
    "    pools = signer_trades['amm_trade'].dropna().unique().tolist()\n",
    "    \n",
    "    signer_features.append({\n",
    "        'signer': signer,\n",
    "        'total_trades': total_trades,\n",
    "        'trades_per_hour': trades_per_hour,\n",
    "        'aggregator_likelihood': aggregator_likelihood,\n",
    "        'late_slot_ratio': late_slot_ratio,\n",
    "        'oracle_backrun_ratio': oracle_backrun_ratio,\n",
    "        'high_bytes_ratio': high_bytes_ratio,\n",
    "        'cluster_ratio': cluster_ratio,\n",
    "        'mev_score': mev_score,\n",
    "        'wash_trading_score': wash_trading_score,\n",
    "        'classification': classification,\n",
    "        'binary_label': binary_label,\n",
    "        'validators': ','.join(validators) if validators else '',\n",
    "        'total_validators': len(validators),\n",
    "        'pools': ','.join(pools) if pools else '',\n",
    "        'total_pools': len(pools)\n",
    "    })\n",
    "\n",
    "df_features = pd.DataFrame(signer_features)\n",
    "print(f\"✓ Created features for {len(df_features)} signers\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 3. MEV EXTRACTION AND STATISTICS\n",
    "# ============================================================================\n",
    "print(\"=\"*80)\n",
    "print(\"3. MEV EXTRACTION AND STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# Separate MEV and Non-MEV\n",
    "mev_df = df_features[df_features['binary_label'] == 1].copy()\n",
    "non_mev_df = df_features[df_features['binary_label'] == 0].copy()\n",
    "\n",
    "print(f\"Total MEV samples: {len(mev_df):,} ({len(mev_df)/len(df_features)*100:.2f}%)\")\n",
    "print(f\"Total Non-MEV samples: {len(non_mev_df):,} ({len(non_mev_df)/len(df_features)*100:.2f}%)\")\n",
    "print()\n",
    "\n",
    "# Feature list for analysis\n",
    "features = [\n",
    "    'total_trades', 'trades_per_hour', 'aggregator_likelihood',\n",
    "    'late_slot_ratio', 'oracle_backrun_ratio', 'high_bytes_ratio',\n",
    "    'cluster_ratio', 'mev_score', 'wash_trading_score'\n",
    "]\n",
    "\n",
    "# 1. MEV Key Statistics\n",
    "print(\"=== MEV Class Key Feature Statistics ===\")\n",
    "print(mev_df[features].describe().round(4))\n",
    "print()\n",
    "\n",
    "# 2. MEV vs Non-MEV Comparison\n",
    "print(\"=== MEV vs Non-MEV Feature Mean Comparison ===\")\n",
    "comparison = pd.DataFrame({\n",
    "    'MEV_Mean': mev_df[features].mean(),\n",
    "    'Non_MEV_Mean': non_mev_df[features].mean(),\n",
    "    'Difference_MEV_Minus_NonMEV': mev_df[features].mean() - non_mev_df[features].mean(),\n",
    "    'Ratio_MEV_to_NonMEV': mev_df[features].mean() / (non_mev_df[features].mean() + 1e-10)\n",
    "})\n",
    "print(comparison.round(4))\n",
    "print()\n",
    "\n",
    "# 3. Classification Breakdown\n",
    "print(\"=== MEV Classification Breakdown ===\")\n",
    "mev_classification_counts = mev_df['classification'].value_counts()\n",
    "print(mev_classification_counts)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 4. TOP MEV WALLETS\n",
    "# ============================================================================\n",
    "print(\"=\"*80)\n",
    "print(\"4. TOP MEV WALLETS\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# Top 20 MEV wallets by mev_score\n",
    "top_mev = mev_df.nlargest(20, 'mev_score')\n",
    "\n",
    "print(\"=== Top 20 High-Risk MEV Wallets (by mev_score) ===\")\n",
    "display_cols = ['signer', 'mev_score', 'oracle_backrun_ratio', 'cluster_ratio', \n",
    "                'total_trades', 'trades_per_hour', 'classification',\n",
    "                'total_validators', 'total_pools']\n",
    "print(top_mev[display_cols].to_string(index=False))\n",
    "print()\n",
    "\n",
    "# Top wallets by total trades\n",
    "print(\"=== Top 10 MEV Wallets by Total Trades ===\")\n",
    "top_by_trades = mev_df.nlargest(10, 'total_trades')\n",
    "print(top_by_trades[display_cols].to_string(index=False))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 5. VALIDATOR AND POOL ANALYSIS\n",
    "# ============================================================================\n",
    "print(\"=\"*80)\n",
    "print(\"5. VALIDATOR AND POOL ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# Validator analysis\n",
    "all_validators = []\n",
    "for validators_str in mev_df['validators']:\n",
    "    if validators_str:\n",
    "        all_validators.extend(validators_str.split(','))\n",
    "\n",
    "validator_counts = Counter(all_validators)\n",
    "print(f\"=== Top 10 Validators Processing MEV Transactions ===\")\n",
    "print(f\"Total unique validators: {len(validator_counts)}\")\n",
    "for validator, count in validator_counts.most_common(10):\n",
    "    print(f\"  {validator[:20]}... : {count} MEV transactions\")\n",
    "print()\n",
    "\n",
    "# Pool/AMM analysis\n",
    "all_pools = []\n",
    "for pools_str in mev_df['pools']:\n",
    "    if pools_str:\n",
    "        all_pools.extend(pools_str.split(','))\n",
    "\n",
    "pool_counts = Counter(all_pools)\n",
    "print(f\"=== Top 10 Pools/AMMs Targeted by MEV Bots ===\")\n",
    "print(f\"Total unique pools: {len(pool_counts)}\")\n",
    "for pool, count in pool_counts.most_common(10):\n",
    "    print(f\"  {pool}: {count} MEV transactions\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 6. PnL ANALYSIS (Estimated from attack patterns)\n",
    "# ============================================================================\n",
    "print(\"=\"*80)\n",
    "print(\"6. PnL ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# Get MEV signers\n",
    "mev_signers = mev_df['signer'].tolist()\n",
    "\n",
    "# Get all trades from MEV signers\n",
    "mev_trade_records = df_trades[df_trades['signer'].isin(mev_signers)].copy()\n",
    "print(f\"✓ Found {len(mev_trade_records):,} trade records from MEV signers\")\n",
    "\n",
    "# Estimate PnL based on attack patterns and MEV scores\n",
    "# This is a simplified estimation - actual PnL would require parsing trade amounts\n",
    "print(\"\\nEstimating PnL based on attack patterns...\")\n",
    "\n",
    "# Calculate estimated attack counts per signer\n",
    "# High mev_score + high cluster_ratio = likely sandwich attacks\n",
    "# High oracle_backrun_ratio = likely back-running attacks\n",
    "# High late_slot_ratio = likely front-running attacks\n",
    "\n",
    "pnl_estimates = []\n",
    "for _, row in mev_df.iterrows():\n",
    "    signer = row['signer']\n",
    "    signer_trades = mev_trade_records[mev_trade_records['signer'] == signer]\n",
    "    \n",
    "    # Estimate attack counts based on patterns\n",
    "    total_trades = row['total_trades']\n",
    "    \n",
    "    # Sandwich attacks: high cluster_ratio + high mev_score\n",
    "    if row['cluster_ratio'] > 0.3 and row['mev_score'] > 0.3:\n",
    "        sandwich_complete = int(total_trades * row['cluster_ratio'] * 0.5)  # Estimate pairs\n",
    "    else:\n",
    "        sandwich_complete = 0\n",
    "    \n",
    "    # Back-running: high oracle_backrun_ratio\n",
    "    back_running = int(total_trades * row['oracle_backrun_ratio'])\n",
    "    \n",
    "    # Front-running: high late_slot_ratio\n",
    "    front_running = int(total_trades * row['late_slot_ratio'] * 0.5)  # Conservative estimate\n",
    "    \n",
    "    # Cost estimation (SOL)\n",
    "    # Sandwich: 0.001 SOL per complete pair (2 transactions)\n",
    "    # Front/Back-running: 0.0005 SOL per transaction\n",
    "    cost_sol = (sandwich_complete * 0.001) + (front_running * 0.0005) + (back_running * 0.0005)\n",
    "    \n",
    "    # Profit estimation (SOL)\n",
    "    # Sandwich: 0.01 SOL per complete pair (1% slippage exploitation)\n",
    "    # Front/Back-running: 0.002 SOL per transaction (0.2% slippage)\n",
    "    profit_sol = (sandwich_complete * 0.01) + (front_running * 0.002) + (back_running * 0.002)\n",
    "    \n",
    "    # Net profit\n",
    "    net_profit_sol = profit_sol - cost_sol\n",
    "    \n",
    "    pnl_estimates.append({\n",
    "        'signer': signer,\n",
    "        'sandwich_complete': sandwich_complete,\n",
    "        'front_running': front_running,\n",
    "        'back_running': back_running,\n",
    "        'total_attacks': sandwich_complete + front_running + back_running,\n",
    "        'cost_sol': cost_sol,\n",
    "        'profit_sol': profit_sol,\n",
    "        'net_profit_sol': net_profit_sol\n",
    "    })\n",
    "\n",
    "pnl_df = pd.DataFrame(pnl_estimates)\n",
    "\n",
    "# Merge PnL estimates with MEV dataframe\n",
    "mev_df = mev_df.merge(pnl_df, on='signer', how='left')\n",
    "\n",
    "# Fill missing values\n",
    "pnl_cols = ['sandwich_complete', 'front_running', 'back_running', 'total_attacks', \n",
    "            'cost_sol', 'profit_sol', 'net_profit_sol']\n",
    "for col in pnl_cols:\n",
    "    if col in mev_df.columns:\n",
    "        mev_df[col] = mev_df[col].fillna(0.0)\n",
    "\n",
    "print(f\"✓ Estimated PnL for {len(pnl_df)} MEV signers\")\n",
    "print()\n",
    "print(\"=== PnL Summary (Estimated) ===\")\n",
    "print(f\"Total Estimated Cost: {mev_df['cost_sol'].sum():.4f} SOL\")\n",
    "print(f\"Total Estimated Profit: {mev_df['profit_sol'].sum():.4f} SOL\")\n",
    "print(f\"Total Estimated Net Profit: {mev_df['net_profit_sol'].sum():.4f} SOL\")\n",
    "print()\n",
    "\n",
    "print(\"=== Top 10 MEV Wallets by Estimated Net Profit ===\")\n",
    "top_pnl = mev_df.nlargest(10, 'net_profit_sol')\n",
    "pnl_display_cols = ['signer', 'mev_score', 'total_attacks', 'sandwich_complete', \n",
    "                   'front_running', 'back_running', 'cost_sol', 'profit_sol', 'net_profit_sol']\n",
    "print(top_pnl[pnl_display_cols].to_string(index=False))\n",
    "print()\n",
    "\n",
    "print(\"Note: PnL estimates are based on attack pattern analysis.\")\n",
    "print(\"      Actual PnL would require parsing trade amounts and prices from trade data.\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 7. VISUALIZATIONS\n",
    "# ============================================================================\n",
    "print(\"=\"*80)\n",
    "print(\"7. VISUALIZATIONS\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# Create output directory\n",
    "output_dir = Path('derived/ml_results_binary')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 1. Scatter plot: mev_score vs oracle_backrun_ratio\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(\n",
    "    data=df_features, \n",
    "    x='oracle_backrun_ratio', \n",
    "    y='mev_score', \n",
    "    hue='binary_label', \n",
    "    palette={0: 'blue', 1: 'red'}, \n",
    "    alpha=0.6,\n",
    "    s=50\n",
    ")\n",
    "plt.title('MEV Separation Visualization: mev_score vs oracle_backrun_ratio\\n(Red = MEV, Blue = Non-MEV)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Oracle Backrun Ratio', fontsize=12)\n",
    "plt.ylabel('MEV Score', fontsize=12)\n",
    "plt.legend(title='Class', labels=['Non-MEV', 'MEV'], fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'mev_separation_scatter.png', dpi=300, bbox_inches='tight')\n",
    "print(f\"✓ Saved: {output_dir / 'mev_separation_scatter.png'}\")\n",
    "plt.show()\n",
    "print()\n",
    "\n",
    "# 2. Scatter plot: cluster_ratio vs mev_score\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(\n",
    "    data=df_features, \n",
    "    x='cluster_ratio', \n",
    "    y='mev_score', \n",
    "    hue='binary_label', \n",
    "    palette={0: 'blue', 1: 'red'}, \n",
    "    alpha=0.6,\n",
    "    s=50\n",
    ")\n",
    "plt.title('MEV Separation Visualization: mev_score vs cluster_ratio\\n(Red = MEV, Blue = Non-MEV)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Cluster Ratio', fontsize=12)\n",
    "plt.ylabel('MEV Score', fontsize=12)\n",
    "plt.legend(title='Class', labels=['Non-MEV', 'MEV'], fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'mev_separation_cluster.png', dpi=300, bbox_inches='tight')\n",
    "print(f\"✓ Saved: {output_dir / 'mev_separation_cluster.png'}\")\n",
    "plt.show()\n",
    "print()\n",
    "\n",
    "# 3. Feature comparison bar chart\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "features_to_plot = ['mev_score', 'oracle_backrun_ratio', 'cluster_ratio', 'late_slot_ratio']\n",
    "for idx, feature in enumerate(features_to_plot):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    comparison_data = pd.DataFrame({\n",
    "        'Class': ['MEV', 'Non-MEV'],\n",
    "        'Mean': [mev_df[feature].mean(), non_mev_df[feature].mean()]\n",
    "    })\n",
    "    sns.barplot(data=comparison_data, x='Class', y='Mean', ax=ax, palette=['red', 'blue'])\n",
    "    ax.set_title(f'{feature.replace(\"_\", \" \").title()}', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Mean Value', fontsize=10)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.suptitle('MEV vs Non-MEV: Key Feature Comparison', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'mev_feature_comparison.png', dpi=300, bbox_inches='tight')\n",
    "print(f\"✓ Saved: {output_dir / 'mev_feature_comparison.png'}\")\n",
    "plt.show()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 8. EXPORT TO CSV\n",
    "# ============================================================================\n",
    "print(\"=\"*80)\n",
    "print(\"8. EXPORT TO CSV\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# 1. All MEV samples\n",
    "mev_export = mev_df.copy()\n",
    "mev_csv_path = output_dir / 'mev_samples_detected.csv'\n",
    "mev_export.to_csv(mev_csv_path, index=False)\n",
    "print(f\"✓ Exported {len(mev_export):,} MEV samples to: {mev_csv_path}\")\n",
    "print()\n",
    "\n",
    "# 2. Top MEV wallets\n",
    "top_mev_export = top_mev.copy()\n",
    "top_mev_csv_path = output_dir / 'top_mev_wallets.csv'\n",
    "top_mev_export.to_csv(top_mev_csv_path, index=False)\n",
    "print(f\"✓ Exported top {len(top_mev_export)} MEV wallets to: {top_mev_csv_path}\")\n",
    "print()\n",
    "\n",
    "# 3. MEV statistics summary\n",
    "stats_summary = {\n",
    "    'Metric': [\n",
    "        'Total_MEV_Samples',\n",
    "        'Total_NonMEV_Samples',\n",
    "        'MEV_Percentage',\n",
    "        'MEV_Mean_mev_score',\n",
    "        'NonMEV_Mean_mev_score',\n",
    "        'MEV_Mean_oracle_backrun_ratio',\n",
    "        'NonMEV_Mean_oracle_backrun_ratio',\n",
    "        'MEV_Mean_cluster_ratio',\n",
    "        'NonMEV_Mean_cluster_ratio',\n",
    "        'Total_MEV_Trades',\n",
    "        'Total_Unique_Validators',\n",
    "        'Total_Unique_Pools'\n",
    "    ],\n",
    "    'Value': [\n",
    "        len(mev_df),\n",
    "        len(non_mev_df),\n",
    "        len(mev_df)/len(df_features)*100,\n",
    "        mev_df['mev_score'].mean(),\n",
    "        non_mev_df['mev_score'].mean(),\n",
    "        mev_df['oracle_backrun_ratio'].mean(),\n",
    "        non_mev_df['oracle_backrun_ratio'].mean(),\n",
    "        mev_df['cluster_ratio'].mean(),\n",
    "        non_mev_df['cluster_ratio'].mean(),\n",
    "        mev_df['total_trades'].sum(),\n",
    "        len(validator_counts),\n",
    "        len(pool_counts)\n",
    "    ]\n",
    "}\n",
    "\n",
    "stats_df = pd.DataFrame(stats_summary)\n",
    "stats_csv_path = output_dir / 'mev_statistics.csv'\n",
    "stats_df.to_csv(stats_csv_path, index=False)\n",
    "print(f\"✓ Exported statistics to: {stats_csv_path}\")\n",
    "print()\n",
    "\n",
    "# 4. Validator and Pool details\n",
    "validator_df = pd.DataFrame({\n",
    "    'validator': list(validator_counts.keys()),\n",
    "    'mev_transaction_count': list(validator_counts.values())\n",
    "}).sort_values('mev_transaction_count', ascending=False)\n",
    "\n",
    "pool_df = pd.DataFrame({\n",
    "    'pool_amm': list(pool_counts.keys()),\n",
    "    'mev_transaction_count': list(pool_counts.values())\n",
    "}).sort_values('mev_transaction_count', ascending=False)\n",
    "\n",
    "validator_csv_path = output_dir / 'mev_validators.csv'\n",
    "pool_csv_path = output_dir / 'mev_pools.csv'\n",
    "\n",
    "validator_df.to_csv(validator_csv_path, index=False)\n",
    "pool_df.to_csv(pool_csv_path, index=False)\n",
    "\n",
    "print(f\"✓ Exported validator info to: {validator_csv_path}\")\n",
    "print(f\"✓ Exported pool info to: {pool_csv_path}\")\n",
    "print()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"EXTRACTION COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "print(f\"All results saved to: {output_dir}\")\n",
    "print(f\"\\nFiles created:\")\n",
    "print(f\"  1. mev_samples_detected.csv - All {len(mev_df):,} MEV samples (with PnL estimates)\")\n",
    "print(f\"  2. top_mev_wallets.csv - Top {len(top_mev_export)} MEV wallets\")\n",
    "print(f\"  3. mev_statistics.csv - Summary statistics\")\n",
    "print(f\"  4. mev_validators.csv - Validator information\")\n",
    "print(f\"  5. mev_pools.csv - Pool/AMM information\")\n",
    "print(f\"  6. mev_separation_scatter.png - Scatter plot visualization\")\n",
    "print(f\"  7. mev_separation_cluster.png - Cluster ratio visualization\")\n",
    "print(f\"  8. mev_feature_comparison.png - Feature comparison chart\")\n",
    "print()\n",
    "print(\"Note: PnL estimates are based on attack pattern analysis.\")\n",
    "print(\"      Actual PnL would require parsing trade amounts and prices from trade data.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
