{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Top Validator & Most Exposed AMM MEV Pattern Analysis\n",
        "\n",
        "## ðŸŽ¯ Overview\n",
        "\n",
        "This notebook analyzes MEV patterns from:\n",
        "- **Top Botted Validator**: `HEL1USMZKAL2odpNBj2oCjffnFGaYwmbGmyewGv1e2TU`\n",
        "  - Trade Count: 28,859\n",
        "  - Bot Count: 408\n",
        "  - Bot Ratio: 1.41%\n",
        "  - MEV Breakdown: 3,119 fat_sandwich, 122 sandwich, 674 front_running, 3,998 back_running\n",
        "\n",
        "- **Most Exposed AMM**: **BisonFi**\n",
        "  - Total Attackers: 432\n",
        "  - Fat Sandwich: 879 attacks\n",
        "  - Front-Running: 1,053 attacks\n",
        "  - Back-Running: 4,075 attacks\n",
        "\n",
        "## ðŸ“‹ MEV Patterns Analyzed\n",
        "\n",
        "Following patterns from \"Hypothetical MEV Bot & Attack Case Studies.md\":\n",
        "\n",
        "1. **Fat Sandwich** (B91 Bot pattern: â‰¥5 TRADEs per slot)\n",
        "2. **Classic Sandwich** (3-4 TRADEs per slot)\n",
        "3. **Front-Running** (Late-slot trades >300ms)\n",
        "4. **Back-Running** (DeezNode Bot pattern: <50ms after oracle)\n",
        "5. **Cross-Slot Sandwich** (2Fast Bot pattern: 4-6 TRADEs across 2+ slots)\n",
        "\n",
        "## ðŸ“š Reference Case Studies\n",
        "\n",
        "- **B91 Bot**: Fat sandwich (4-10+ TRADEs per slot)\n",
        "- **Arsc Bot**: Cross-slot sandwich + oracle manipulation\n",
        "- **DeezNode Bot**: Oracle-timed back-running (<50ms)\n",
        "- **2Fast Bot**: Cross-slot wide sandwich (4-6 TRADEs across 2+ slots)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import os\n",
        "\n",
        "# Configuration\n",
        "TOP_VALIDATOR = 'HEL1USMZKAL2odpNBj2oCjffnFGaYwmbGmyewGv1e2TU'\n",
        "MOST_EXPOSED_AMM = 'BisonFi'  # Highest MEV activity\n",
        "\n",
        "# MEV Detection Thresholds\n",
        "FAT_SANDWICH_MIN_TRADES = 5  # B91 Bot pattern\n",
        "CLASSIC_SANDWICH_MIN_TRADES = 3\n",
        "FRONT_RUNNING_THRESHOLD_MS = 300000  # >300ms\n",
        "BACK_RUNNING_THRESHOLD_MS = 50  # <50ms\n",
        "CROSS_SLOT_MAX_SLOTS = 3\n",
        "\n",
        "# Output directory\n",
        "OUTPUT_DIR = 'derived/top_validator_amm_analysis'\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"TOP VALIDATOR & MOST EXPOSED AMM MEV PATTERN ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "print()\n",
        "print(f\"Top Botted Validator: {TOP_VALIDATOR}\")\n",
        "print(f\"Most Exposed AMM: {MOST_EXPOSED_AMM}\")\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Loading & Filtering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load cleaned dataset\n",
        "# Try multiple possible paths\n",
        "possible_paths = [\n",
        "    '/Users/aileen/Downloads/pamm/pamm_clean_final.parquet',\n",
        "    '../01_data_cleaning/outputs/pamm_clean_final.parquet',\n",
        "    'notebooks/01_data_cleaning/outputs/pamm_clean_final.parquet',\n",
        "    'pamm_clean_final.parquet'\n",
        "]\n",
        "\n",
        "df_clean = None\n",
        "for path in possible_paths:\n",
        "    try:\n",
        "        df_clean = pd.read_parquet(path)\n",
        "        print(f\"âœ“ Loaded data from: {path}\")\n",
        "        break\n",
        "    except (FileNotFoundError, OSError):\n",
        "        continue\n",
        "\n",
        "if df_clean is None:\n",
        "    raise FileNotFoundError(\"Could not find pamm_clean_final.parquet. Please check the path.\")\n",
        "\n",
        "print(f\"âœ“ Loaded {len(df_clean):,} total records\")\n",
        "\n",
        "# Filter to top validator\n",
        "df_validator = df_clean[df_clean['validator'] == TOP_VALIDATOR].copy()\n",
        "print(f\"âœ“ Records from top validator: {len(df_validator):,}\")\n",
        "\n",
        "# Filter to most exposed AMM\n",
        "amm_mask = (\n",
        "    (df_validator['amm_oracle'] == MOST_EXPOSED_AMM) | \n",
        "    (df_validator['amm_trade'] == MOST_EXPOSED_AMM)\n",
        ")\n",
        "df_amm = df_validator[amm_mask].copy()\n",
        "print(f\"âœ“ Records from {MOST_EXPOSED_AMM}: {len(df_amm):,}\")\n",
        "\n",
        "# Separate TRADE and ORACLE events\n",
        "df_trades = df_amm[df_amm['kind'] == 'TRADE'].copy()\n",
        "df_oracles = df_amm[df_amm['kind'] == 'ORACLE'].copy()\n",
        "\n",
        "print(f\"âœ“ TRADE events: {len(df_trades):,}\")\n",
        "print(f\"âœ“ ORACLE events: {len(df_oracles):,}\")\n",
        "\n",
        "# Sort by time\n",
        "df_trades = df_trades.sort_values('ms_time').reset_index(drop=True)\n",
        "df_oracles = df_oracles.sort_values('ms_time').reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Fat Sandwich Detection (B91 Bot Pattern: â‰¥5 TRADEs per slot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"OPTIMIZED ANALYSIS: Top Validator & BisonFi MEV Patterns\")\n",
        "print(\"=\"*80)\n",
        "print()\n",
        "\n",
        "# Ensure slot is integer\n",
        "df_amm['slot'] = df_amm['slot'].astype(int)\n",
        "df_amm = df_amm.sort_values('ms_time').reset_index(drop=True)\n",
        "\n",
        "# Slot-level grouping\n",
        "slot_groups = df_amm.groupby('slot')\n",
        "\n",
        "# 1. FAT SANDWICH (B91: â‰¥5 TRADEs/slot)\n",
        "fat_slots = slot_groups.filter(lambda x: (x['kind'] == 'TRADE').sum() >= FAT_SANDWICH_MIN_TRADES)\n",
        "fat_sandwich_count = fat_slots['slot'].nunique() if len(fat_slots) > 0 else 0\n",
        "fat_sandwich_trades = len(fat_slots[fat_slots['kind'] == 'TRADE']) if len(fat_slots) > 0 else 0\n",
        "print(f\"âœ“ Fat Sandwich slots (â‰¥{FAT_SANDWICH_MIN_TRADES} TRADEs, B91 pattern): {fat_sandwich_count:,}\")\n",
        "print(f\"  â†’ Total trades in fat sandwich slots: {fat_sandwich_trades:,}\")\n",
        "\n",
        "# 2. CLASSIC SANDWICH (3-4 TRADEs/slot)\n",
        "classic_slots = slot_groups.filter(lambda x: 3 <= (x['kind'] == 'TRADE').sum() <= 4)\n",
        "classic_sandwich_count = classic_slots['slot'].nunique() if len(classic_slots) > 0 else 0\n",
        "classic_sandwich_trades = len(classic_slots[classic_slots['kind'] == 'TRADE']) if len(classic_slots) > 0 else 0\n",
        "print(f\"âœ“ Classic Sandwich slots (3-4 TRADEs): {classic_sandwich_count:,}\")\n",
        "print(f\"  â†’ Total trades in classic sandwich slots: {classic_sandwich_trades:,}\")\n",
        "\n",
        "# 3. CROSS-SLOT SANDWICH (2Fast: 4-6 TRADEs across 2+ slots, continuous)\n",
        "# Detect consecutive slots with 4-6 total TRADEs\n",
        "df_trades_sorted = df_amm[df_amm['kind'] == 'TRADE'].sort_values('slot').copy()\n",
        "df_trades_sorted['slot_diff'] = df_trades_sorted['slot'].diff()\n",
        "df_trades_sorted['consecutive_group'] = (df_trades_sorted['slot_diff'] > 1).cumsum()\n",
        "\n",
        "cross_slot_candidates = []\n",
        "for group_id, group in df_trades_sorted.groupby('consecutive_group'):\n",
        "    if 4 <= len(group) <= 6 and group['slot'].nunique() >= 2:\n",
        "        cross_slot_candidates.append(group_id)\n",
        "\n",
        "cross_sandwich_count = len(cross_slot_candidates)\n",
        "cross_sandwich_trades = len(df_trades_sorted[df_trades_sorted['consecutive_group'].isin(cross_slot_candidates)])\n",
        "print(f\"âœ“ Cross-Slot Sandwich (4-6 TRADEs across 2+ slots, 2Fast pattern): ~{cross_sandwich_count:,}\")\n",
        "print(f\"  â†’ Total trades in cross-slot patterns: {cross_sandwich_trades:,}\")\n",
        "\n",
        "# 4. FRONT-RUNNING (Late-slot TRADE >300ms)\n",
        "# Using us_since_first_shred > 300000 (300ms in microseconds)\n",
        "if 'us_since_first_shred' in df_amm.columns:\n",
        "    front_running = df_amm[\n",
        "        (df_amm['kind'] == 'TRADE') & \n",
        "        (df_amm['us_since_first_shred'] > FRONT_RUNNING_THRESHOLD_MS)\n",
        "    ].copy()\n",
        "    front_running_count = len(front_running)\n",
        "    print(f\"âœ“ Front-Running trades (>300ms late-slot): {front_running_count:,}\")\n",
        "else:\n",
        "    front_running = pd.DataFrame()\n",
        "    front_running_count = 0\n",
        "    print(\"âš  Front-Running: 'us_since_first_shred' column not found\")\n",
        "\n",
        "# 5. BACK-RUNNING (DeezNode: TRADE <50ms after ORACLE)\n",
        "df_amm_sorted = df_amm.sort_values('ms_time').reset_index(drop=True).copy()\n",
        "df_amm_sorted['prev_kind'] = df_amm_sorted['kind'].shift(1)\n",
        "df_amm_sorted['prev_ms_time'] = df_amm_sorted['ms_time'].shift(1)\n",
        "df_amm_sorted['lag_ms'] = df_amm_sorted['ms_time'] - df_amm_sorted['prev_ms_time']\n",
        "\n",
        "back_running = df_amm_sorted[\n",
        "    (df_amm_sorted['kind'] == 'TRADE') & \n",
        "    (df_amm_sorted['prev_kind'] == 'ORACLE') & \n",
        "    (df_amm_sorted['lag_ms'] < BACK_RUNNING_THRESHOLD_MS) &\n",
        "    (df_amm_sorted['lag_ms'] >= 0)  # Ensure positive lag\n",
        "].copy()\n",
        "back_running_count = len(back_running)\n",
        "print(f\"âœ“ Back-Running trades (<{BACK_RUNNING_THRESHOLD_MS}ms after Oracle, DeezNode pattern): {back_running_count:,}\")\n",
        "\n",
        "# Summary\n",
        "print()\n",
        "print(\"=\"*80)\n",
        "print(\"MEV PATTERN SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Fat Sandwich (B91):     {fat_sandwich_count:,} slots, {fat_sandwich_trades:,} trades\")\n",
        "print(f\"Classic Sandwich:       {classic_sandwich_count:,} slots, {classic_sandwich_trades:,} trades\")\n",
        "print(f\"Cross-Slot (2Fast):    ~{cross_sandwich_count:,} patterns, {cross_sandwich_trades:,} trades\")\n",
        "print(f\"Front-Running:         {front_running_count:,} trades\")\n",
        "print(f\"Back-Running (DeezNode): {back_running_count:,} trades\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Visualization: Slot Density & Lag Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create output directory for images\n",
        "os.makedirs(os.path.join(OUTPUT_DIR, 'images'), exist_ok=True)\n",
        "\n",
        "# 1. Slot TRADE density + Oracle overlay (sampled for visualization)\n",
        "# Sample slots if too many for visualization\n",
        "unique_slots = df_amm['slot'].unique()\n",
        "if len(unique_slots) > 500:\n",
        "    sample_slots = np.random.choice(unique_slots, size=500, replace=False)\n",
        "    df_amm_viz = df_amm[df_amm['slot'].isin(sample_slots)].copy()\n",
        "    print(f\"Sampling {len(sample_slots):,} slots for visualization (out of {len(unique_slots):,} total)\")\n",
        "else:\n",
        "    df_amm_viz = df_amm.copy()\n",
        "\n",
        "slot_groups_viz = df_amm_viz.groupby('slot')\n",
        "slot_trade_counts = slot_groups_viz['kind'].apply(lambda x: (x == 'TRADE').sum()).reset_index(name='trade_count')\n",
        "slot_oracle_counts = slot_groups_viz['kind'].apply(lambda x: (x == 'ORACLE').sum()).reset_index(name='oracle_count')\n",
        "slot_counts = slot_trade_counts.merge(slot_oracle_counts, on='slot', how='outer').fillna(0)\n",
        "slot_counts = slot_counts.sort_values('slot').head(200)  # Show first 200 slots\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "x_pos = np.arange(len(slot_counts))\n",
        "width = 0.35\n",
        "\n",
        "plt.bar(x_pos - width/2, slot_counts['trade_count'], width, label='TRADE', alpha=0.7, color='#FF6B6B')\n",
        "plt.bar(x_pos + width/2, slot_counts['oracle_count'], width, label='ORACLE', alpha=0.7, color='#4ECDC4')\n",
        "\n",
        "plt.title('TRADE vs ORACLE per Slot in Top Validator & BisonFi (Sample)', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('Event Count', fontsize=12)\n",
        "plt.xlabel('Slot Index (Sample)', fontsize=12)\n",
        "plt.legend(fontsize=11)\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "\n",
        "slot_density_path = os.path.join(OUTPUT_DIR, 'images', 'validator_amm_slot_density.png')\n",
        "plt.savefig(slot_density_path, dpi=300, bbox_inches='tight')\n",
        "print(f\"âœ“ Saved slot density chart: {slot_density_path}\")\n",
        "plt.show()\n",
        "\n",
        "# 2. Lag histogram for back-running\n",
        "if len(back_running) > 0:\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.histplot(back_running['lag_ms'], bins=30, kde=True, color='#FF6B6B', edgecolor='black', alpha=0.7)\n",
        "    plt.axvline(BACK_RUNNING_THRESHOLD_MS, color='red', linestyle='--', linewidth=2, label=f'{BACK_RUNNING_THRESHOLD_MS}ms threshold')\n",
        "    plt.title('Back-Running Lag Distribution (<50ms peak = DeezNode Pattern)', fontsize=14, fontweight='bold')\n",
        "    plt.xlabel('Lag after Oracle (ms)', fontsize=12)\n",
        "    plt.ylabel('Frequency', fontsize=12)\n",
        "    plt.legend(fontsize=11)\n",
        "    plt.grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    # Add statistics\n",
        "    mean_lag = back_running['lag_ms'].mean()\n",
        "    median_lag = back_running['lag_ms'].median()\n",
        "    plt.axvline(mean_lag, color='blue', linestyle=':', linewidth=1.5, label=f'Mean: {mean_lag:.1f}ms')\n",
        "    plt.axvline(median_lag, color='green', linestyle=':', linewidth=1.5, label=f'Median: {median_lag:.1f}ms')\n",
        "    plt.legend(fontsize=10)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    lag_hist_path = os.path.join(OUTPUT_DIR, 'images', 'back_running_lag_distribution.png')\n",
        "    plt.savefig(lag_hist_path, dpi=300, bbox_inches='tight')\n",
        "    print(f\"âœ“ Saved back-running lag histogram: {lag_hist_path}\")\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"\\nBack-Running Statistics:\")\n",
        "    print(f\"  Mean lag: {mean_lag:.2f} ms\")\n",
        "    print(f\"  Median lag: {median_lag:.2f} ms\")\n",
        "    print(f\"  Min lag: {back_running['lag_ms'].min():.2f} ms\")\n",
        "    print(f\"  Max lag: {back_running['lag_ms'].max():.2f} ms\")\n",
        "    print(f\"  <10ms: {(back_running['lag_ms'] < 10).sum():,} trades ({100*(back_running['lag_ms'] < 10).sum()/len(back_running):.1f}%)\")\n",
        "    print(f\"  10-50ms: {((back_running['lag_ms'] >= 10) & (back_running['lag_ms'] < 50)).sum():,} trades ({100*((back_running['lag_ms'] >= 10) & (back_running['lag_ms'] < 50)).sum()/len(back_running):.1f}%)\")\n",
        "else:\n",
        "    print(\"âš  No back-running trades detected for lag analysis\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Bot Concentration Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bot concentration: unique signers per slot\n",
        "if 'signer' in df_amm.columns:\n",
        "    bot_trades_per_slot = slot_groups['signer'].nunique()\n",
        "    avg_bots_per_slot = bot_trades_per_slot.mean()\n",
        "    max_bots_per_slot = bot_trades_per_slot.max()\n",
        "    median_bots_per_slot = bot_trades_per_slot.median()\n",
        "    \n",
        "    print(f\"Bot Concentration Statistics:\")\n",
        "    print(f\"  Average unique signers per slot: {avg_bots_per_slot:.1f}\")\n",
        "    print(f\"  Median unique signers per slot: {median_bots_per_slot:.1f}\")\n",
        "    print(f\"  Max unique signers per slot: {max_bots_per_slot}\")\n",
        "    print(f\"  Total unique signers: {df_amm[df_amm['kind'] == 'TRADE']['signer'].nunique():,}\")\n",
        "    \n",
        "    # Visualize bot concentration\n",
        "    plt.figure(figsize=(14, 6))\n",
        "    # Sample for visualization if too many slots\n",
        "    if len(bot_trades_per_slot) > 500:\n",
        "        sample_indices = np.random.choice(len(bot_trades_per_slot), size=500, replace=False)\n",
        "        bot_counts_sample = bot_trades_per_slot.iloc[sample_indices]\n",
        "    else:\n",
        "        bot_counts_sample = bot_trades_per_slot\n",
        "    \n",
        "    plt.hist(bot_counts_sample, bins=30, color='#95E1D3', edgecolor='black', alpha=0.7)\n",
        "    plt.axvline(avg_bots_per_slot, color='red', linestyle='--', linewidth=2, label=f'Mean: {avg_bots_per_slot:.1f}')\n",
        "    plt.title('Bot Concentration: Unique Signers per Slot', fontsize=14, fontweight='bold')\n",
        "    plt.xlabel('Number of Unique Signers (Bots)', fontsize=12)\n",
        "    plt.ylabel('Frequency (Slots)', fontsize=12)\n",
        "    plt.legend(fontsize=11)\n",
        "    plt.grid(axis='y', alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    \n",
        "    bot_concentration_path = os.path.join(OUTPUT_DIR, 'images', 'bot_concentration_per_slot.png')\n",
        "    plt.savefig(bot_concentration_path, dpi=300, bbox_inches='tight')\n",
        "    print(f\"âœ“ Saved bot concentration chart: {bot_concentration_path}\")\n",
        "    plt.show()\n",
        "    \n",
        "    # Top signers by trade count\n",
        "    top_signers = df_amm[df_amm['kind'] == 'TRADE']['signer'].value_counts().head(20)\n",
        "    print(f\"\\nTop 20 Signers by Trade Count:\")\n",
        "    print(top_signers.to_string())\n",
        "    \n",
        "else:\n",
        "    print(\"âš  'signer' column not found - skipping bot concentration analysis\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Deep Root Cause Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate key metrics for root cause analysis\n",
        "total_trades = len(df_trades)\n",
        "total_oracles = len(df_oracles)\n",
        "unique_slots = df_amm['slot'].nunique()\n",
        "unique_signers = df_amm[df_amm['kind'] == 'TRADE']['signer'].nunique() if 'signer' in df_amm.columns else 0\n",
        "\n",
        "# Trade density metrics\n",
        "trades_per_slot = total_trades / unique_slots if unique_slots > 0 else 0\n",
        "oracles_per_slot = total_oracles / unique_slots if unique_slots > 0 else 0\n",
        "\n",
        "# Front-running ratio\n",
        "front_running_ratio = front_running_count / total_trades if total_trades > 0 else 0\n",
        "\n",
        "# Back-running ratio\n",
        "back_running_ratio = back_running_count / total_trades if total_trades > 0 else 0\n",
        "\n",
        "# Fat sandwich ratio\n",
        "fat_sandwich_ratio = fat_sandwich_count / unique_slots if unique_slots > 0 else 0\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"DEEP ROOT CAUSE ANALYSIS: Top Validator HEL1US... & BisonFi\")\n",
        "print(\"=\"*80)\n",
        "print()\n",
        "\n",
        "root_causes = f\"\"\"\n",
        "### 1. Validator Slot Attractiveness\n",
        "- **High Trade Volume**: {total_trades:,} trades across {unique_slots:,} slots\n",
        "- **Trade Density**: {trades_per_slot:.2f} trades/slot (high = bot spam target)\n",
        "- **Bot Concentration**: {unique_signers:,} unique signers (high = bot ecosystem targeting)\n",
        "- **Root Cause**: HEL1US... validator has stable leader slot + high trade count ({total_trades:,}) \n",
        "  â†’ Bots spam non-Jito bundles to capture MEV opportunities\n",
        "\n",
        "### 2. AMM Oracle Vulnerability (BisonFi)\n",
        "- **Oracle Frequency**: {oracles_per_slot:.2f} oracles/slot\n",
        "- **Back-Running Dominance**: {back_running_count:,} back-running trades ({back_running_ratio*100:.1f}% of all trades)\n",
        "- **Back-Running Lag**: {f\"Mean {back_running['lag_ms'].mean():.1f}ms, Median {back_running['lag_ms'].median():.1f}ms\" if len(back_running) > 0 else \"N/A (no back-running detected)\"}\n",
        "- **Root Cause**: BisonFi oracle updates are slow/inefficient â†’ DeezNode bots exploit <50ms window\n",
        "  â†’ PropAMM architecture lacks protection against oracle-timed attacks\n",
        "\n",
        "### 3. Fat Sandwich Dominance (B91 Pattern)\n",
        "- **Fat Sandwich Slots**: {fat_sandwich_count:,} slots ({fat_sandwich_ratio*100:.1f}% of all slots)\n",
        "- **Fat Sandwich Trades**: {fat_sandwich_trades:,} trades\n",
        "- **Root Cause**: â‰¥5 trades/slot pattern = meme/high-volume pairs with shallow liquidity\n",
        "  â†’ Large victim trades create significant slippage â†’ B91 bots profit from fat sandwich\n",
        "\n",
        "### 4. Cross-Slot Opportunity (2Fast Pattern)\n",
        "- **Cross-Slot Patterns**: ~{cross_sandwich_count:,} detected patterns\n",
        "- **Cross-Slot Trades**: {cross_sandwich_trades:,} trades\n",
        "- **Root Cause**: Validator slot boundary delays â†’ 2Fast bots insert multi-trade patterns\n",
        "  across 2+ consecutive slots (4-6 trades total)\n",
        "\n",
        "### 5. Front-Running Activity\n",
        "- **Front-Running Trades**: {front_running_count:,} trades ({front_running_ratio*100:.1f}% of all trades)\n",
        "- **Root Cause**: Late-slot trades (>300ms) = bots exploiting slot timing to front-run\n",
        "  â†’ Validator slot length/stability enables predictable timing attacks\n",
        "\n",
        "### 6. Systemic Bot Ecosystem\n",
        "- **Bot Concentration**: {unique_signers:,} unique signers targeting this validator/AMM combination\n",
        "- **Pattern Distribution**:\n",
        "  * Fat Sandwich (B91): {fat_sandwich_count:,} slots\n",
        "  * Classic Sandwich: {classic_sandwich_count:,} slots  \n",
        "  * Cross-Slot (2Fast): ~{cross_sandwich_count:,} patterns\n",
        "  * Back-Running (DeezNode): {back_running_count:,} trades\n",
        "  * Front-Running: {front_running_count:,} trades\n",
        "- **Root Cause**: Solana leader slot concentration + oracle heterogeneity\n",
        "  â†’ Bots systematically target specific validator/AMM combinations to maximize profit\n",
        "  â†’ Low-latency infrastructure + priority fee targeting = competitive advantage\n",
        "\n",
        "### Summary: Why This Validator/AMM is a Hotspot\n",
        "1. **Validator**: High trade volume + stable leader slot = predictable MEV opportunities\n",
        "2. **AMM**: Slow oracle updates + PropAMM architecture = vulnerable to back-running\n",
        "3. **Liquidity**: Shallow pools on high-volume pairs = large slippage = fat sandwich profit\n",
        "4. **Timing**: Slot boundary delays + late-slot trades = cross-slot + front-running opportunities\n",
        "5. **Ecosystem**: 400+ bots competing = sophisticated attack patterns (B91/DeezNode/2Fast)\n",
        "\"\"\"\n",
        "\n",
        "print(root_causes)\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Save root cause analysis to file\n",
        "root_cause_path = os.path.join(OUTPUT_DIR, 'root_cause_analysis.txt')\n",
        "with open(root_cause_path, 'w') as f:\n",
        "    f.write(\"=\"*80 + \"\\n\")\n",
        "    f.write(\"DEEP ROOT CAUSE ANALYSIS: Top Validator HEL1US... & BisonFi\\n\")\n",
        "    f.write(\"=\"*80 + \"\\n\\n\")\n",
        "    f.write(root_causes)\n",
        "print(f\"âœ“ Saved root cause analysis: {root_cause_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Pattern Comparison & Summary Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive summary DataFrame\n",
        "summary_data = {\n",
        "    'Pattern': [\n",
        "        'Fat Sandwich (B91)',\n",
        "        'Classic Sandwich',\n",
        "        'Cross-Slot (2Fast)',\n",
        "        'Front-Running',\n",
        "        'Back-Running (DeezNode)'\n",
        "    ],\n",
        "    'Slots/Patterns': [\n",
        "        fat_sandwich_count,\n",
        "        classic_sandwich_count,\n",
        "        cross_sandwich_count,\n",
        "        '-',\n",
        "        '-'\n",
        "    ],\n",
        "    'Trades': [\n",
        "        fat_sandwich_trades,\n",
        "        classic_sandwich_trades,\n",
        "        cross_sandwich_trades,\n",
        "        front_running_count,\n",
        "        back_running_count\n",
        "    ],\n",
        "    'Percentage of Total Trades': [\n",
        "        f\"{100*fat_sandwich_trades/total_trades:.1f}%\" if total_trades > 0 else \"0%\",\n",
        "        f\"{100*classic_sandwich_trades/total_trades:.1f}%\" if total_trades > 0 else \"0%\",\n",
        "        f\"{100*cross_sandwich_trades/total_trades:.1f}%\" if total_trades > 0 else \"0%\",\n",
        "        f\"{100*front_running_count/total_trades:.1f}%\" if total_trades > 0 else \"0%\",\n",
        "        f\"{100*back_running_count/total_trades:.1f}%\" if total_trades > 0 else \"0%\"\n",
        "    ],\n",
        "    'Reference Bot': [\n",
        "        'B91 Bot',\n",
        "        'Generic Sandwich',\n",
        "        '2Fast Bot',\n",
        "        'Late-Slot Exploit',\n",
        "        'DeezNode Bot'\n",
        "    ]\n",
        "}\n",
        "\n",
        "df_summary = pd.DataFrame(summary_data)\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"MEV PATTERN SUMMARY TABLE\")\n",
        "print(\"=\"*80)\n",
        "print(df_summary.to_string(index=False))\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Save summary to CSV\n",
        "summary_csv_path = os.path.join(OUTPUT_DIR, 'mev_pattern_summary.csv')\n",
        "df_summary.to_csv(summary_csv_path, index=False)\n",
        "print(f\"\\nâœ“ Saved pattern summary: {summary_csv_path}\")\n",
        "\n",
        "# Visualize pattern comparison\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Bar chart: Trades by pattern\n",
        "pattern_names = df_summary['Pattern'].values\n",
        "trade_counts = df_summary['Trades'].values\n",
        "colors = ['#FF6B6B', '#4ECDC4', '#95E1D3', '#F38181', '#AA96DA']\n",
        "\n",
        "ax1.barh(pattern_names, trade_counts, color=colors, alpha=0.7, edgecolor='black')\n",
        "ax1.set_xlabel('Number of Trades', fontsize=12)\n",
        "ax1.set_title('MEV Pattern Comparison: Trade Counts', fontsize=14, fontweight='bold')\n",
        "ax1.grid(axis='x', alpha=0.3)\n",
        "\n",
        "# Add value labels\n",
        "for i, v in enumerate(trade_counts):\n",
        "    ax1.text(v + max(trade_counts)*0.01, i, f'{v:,}', va='center', fontsize=10)\n",
        "\n",
        "# Pie chart: Distribution of MEV patterns\n",
        "ax2.pie(trade_counts, labels=pattern_names, autopct='%1.1f%%', colors=colors, \n",
        "        startangle=90, textprops={'fontsize': 10})\n",
        "ax2.set_title('MEV Pattern Distribution', fontsize=14, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "comparison_path = os.path.join(OUTPUT_DIR, 'images', 'mev_pattern_comparison.png')\n",
        "plt.savefig(comparison_path, dpi=300, bbox_inches='tight')\n",
        "print(f\"âœ“ Saved pattern comparison chart: {comparison_path}\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
